---
title: Agent Creation
description: In-depth guide to creating and configuring Brain Framework agents
---

import { Steps, Tabs, TabItem, Aside } from '@astrojs/starlight/components';
import ExternalLink from "../../../components/ExternalLink.astro"

Brain Framework uses a builder pattern for creating agents, allowing flexible configuration of databases, clients, model providers, plugins and character settings.

Before diving into individual configuration options, here's how all the pieces come together using Brain Framework's builder pattern:


```typescript
import { AgentBuilder, ModelProviderName } from "@iqai/agent";
import SqliteAdapter from "@elizaos/adapter-sqlite";
import DirectClient from "@elizaos/client-direct";


async function main() {
  const agent = new AgentBuilder()
    .withDatabase(SqliteAdapter)
    .withClient(DirectClient)
    .withModelProvider(ModelProviderName.OPENAI, process.env.OPENAI_API_KEY)
    .withCharacter({
      name: "MyBot",
      bio: "A helpful assistant",
      username: "mybot",
      messageExamples: ["Hello! How can I help?"],
      lore: ["Created to assist users"],
      style: {
        all: ["Professional"],
        chat: ["Friendly"],
        post: ["Clear"]
      }
    })
    .build();

  await agent.start();
}

main().catch(console.error);
```

The sections below detail each configuration option available through the builder pattern.

## Database Configuration

The database adapter provides persistence for the agent. Available options:

<Tabs>
  <TabItem label="SQLite">
    ```typescript
    import SqliteAdapter from "@elizaos/adapter-sqlite";


    const sqliteAdapter = new SqliteDatabaseAdapter(
      new Database("./data/db.sqlite")
    );

    // Add database to agent
    .withDatabase(sqliteAdapter)
    ```
  </TabItem>
  <TabItem label="PostgreSQL">
    ```typescript
    import { PostgresDatabaseAdapter } from "@elizaos/adapter-postgres";

    const postgresAdapter = new PostgresDatabaseAdapter({
      connectionString: "postgresql://user:pass@localhost:5432/db"
    });

    // Add database to agent
    .withDatabase(postgresAdapter)
    ```
  </TabItem>
  <TabItem label="Supabase">
    ```typescript
    import { SupabaseDatabaseAdapter } from "@elizaos/adapter-supabase";

    const supabaseAdapter = new SupabaseDatabaseAdapter({
      url: process.env.SUPABASE_URL,
      key: process.env.SUPABASE_KEY
    });

    // Add database to agent
    .withDatabase(supabaseAdapter)
    ```
  </TabItem>
</Tabs>

For more database adapters, visit <a href="https://elizaos.github.io/eliza/docs/packages/adapters/" target="_blank">ElizaOS Database Adapters</a>


## Clients

Clients determine how your agent can communicate:

```typescript
// Available clients
.withClient(DirectClient)    // Direct chat
.withClient(TelegramClient) // Telegram bot
.withClient(TwitterClient)   // Twitter bot
```

Each client may require specific environment variables. Example:
- Telegram: `TELEGRAM_BOT_TOKEN`
- Twitter: `TWITTER_API_KEY`, `TWITTER_API_SECRET`, etc.

Browse all available client plugins at <ExternalLink href="https://github.com/orgs/elizaos-plugins/repositories?language=&q=client-&sort=&type=all">ElizaOS Client Plugins</ExternalLink>


## Model Provider

Configure the AI model powering your agent:

```typescript
.withModelProvider(
  ModelProviderName.OPENAI,
  process.env.OPENAI_API_KEY
)
```
For available model providers, visit <ExternalLink href="https://github.com/elizaOS/eliza/blob/908fff3a14bb2c0c12bc34b9946477cda8de48e4/packages/core/src/types.ts#L203">ElizaOS Models</ExternalLink>

## Configuring model names

Default model names are set for each model provider. You can check them out here <ExternalLink href="https://github.com/elizaOS/eliza/blob/908fff3a14bb2c0c12bc34b9946477cda8de48e4/packages/core/src/models.ts">ElizaOS model settings</ExternalLink>

You can also set your own model names in the .env file:

```bash
# OpenAI
OPENAI_API_KEY= # OpenAI API key
OPENAI_API_URL= # OpenAI API URL
SMALL_OPENAI_MODEL= # OpenAI model name
MEDIUM_OPENAI_MODEL=
LARGE_OPENAI_MODEL=
EMBEDDING_OPENAI_MODEL=
# Anthropic
ANTHROPIC_API_KEY= # Anthropic API key
SMALL_ANTHROPIC_MODEL=
MEDIUM_ANTHROPIC_MODEL=
LARGE_ANTHROPIC_MODEL=
...
```
## Plugins

Brain Framework supports both its native plugins and ElizaOS plugins. Here's how to add plugins to your agent:

```typescript
// Initialize plugins
const fraxlendPlugin = await createFraxlendPlugin({
  chain: fraxtal,
  walletPrivateKey: process.env.WALLET_PRIVATE_KEY,
});

const odosPlugin = await createOdosPlugin({
  chain: fraxtal,
  walletPrivateKey: process.env.WALLET_PRIVATE_KEY,
});

// Add plugins to agent
.withPlugins([fraxlendPlugin, odosPlugin])
```

Browse available plugins:
- <ExternalLink href="https://github.com/IQAIcom/brain/tree/main/packages">Brain Framework Plugins</ExternalLink>
- <ExternalLink href="https://github.com/elizaos-plugins">ElizaOS Plugins</ExternalLink>

## Character Configuration

Define your agent's personality and behavior:

```typescript
.withCharacter({
  name: "MyBot",        // Display name
  bio: "Description",   // Bot's description/purpose
  username: "mybot",    // Unique identifier

  // Example interactions
  messageExamples: [
    "Hello, how can I help?",
    "Let me check that for you."
  ],

  // Additional context/background
  lore: [
    "Created to help with customer service",
    "Specializes in technical support"
  ],

  // Response styling
  style: {
    all: ["Professional", "Helpful"],     // General style
    chat: ["Conversational", "Friendly"], // Chat-specific style
    post: ["Informative", "Clear"]        // Social media post style
  }
})
```

For detailed character configuration options, visit <ExternalLink  href="https://elizaos.github.io/eliza/docs/core/characterfile/">ElizaOS Character Configuration</ExternalLink>


## Telemetry Integration

Enables LLM request/response telemetry with Open Telemetry via Vercel AI SDK.

For example, here is how you can enable telemetry with langsmith:

```typescript
import { Client } from "langsmith";
import { AISDKExporter } from "langsmith/vercel";

// Initialize Langfuse tracer
const tracer = new AISDKExporter({ client: new Client() })

// Enable telemetry with Langfuse tracer
const agent = new AgentBuilder()
  .withTelemetry(tracer)
  //... other configurations ...
  .build();
```

Similarly, you can enable telemetry with other providers like Langfuse, Honeycomb, laminar etc.

for more information on observability integrations, see the <ExternalLink href="https://sdk.vercel.ai/providers/observability">Vercel AI SDK documentation</ExternalLink>.

## Error Handling

Implement proper error handling for production:

```typescript
async function main() {
  try {
    const agent = new AgentBuilder()
      // ... configuration
      .build();

    await agent.start();
  } catch (error) {
    console.error("Failed to start agent:", error);
    process.exit(1);
  }
}

main().catch(console.error);
```

<Aside type="tip">
Remember to:
- Configure proper database persistence
- Set up all required environment variables
- Handle errors appropriately
- Monitor agent performance
</Aside>
